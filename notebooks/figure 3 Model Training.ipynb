{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Figure 3 - Model training on whole-brain recordings of spontaneous activity of larval zebrafish\n",
    "\n",
    "Light-sheet fluorescence microscopy is an innovative imaging technique that enables the recording of whole-brain activity of small vertebrates (larval zebrafish) at the neuronal level (~40K neurons) simultaneously. The observed patterns of spontaneous activity signify a random exploration of the neuronal state space, which is restricted by the underlying assembly organization of neurons.\n",
    "\n",
    "In order to analyze these patterns, the cRBM is utilized to identify physiologically meaningful neural assemblies that combine to form successive brain states. Additionally, the RTRBM is used with transfer learning to determine suggestive temporal connections between these assemblies. The cRBM and RTRBM are also used to accurately replicate the mean activity and pairwise correlation, as well as pairwise time-shifted correlation statistics of the recordings using a limited number of parameters. These statistics are then used to compare the performance of the cRBM and RTRBM. Approximately 200 such neural assemblies are identified and analyzed using these techniques.\n",
    "\n",
    "This paper is the source of both the data and the cRBM model:\n",
    "van der Plas, T., Tubiana, J., Le Goc, G., Migault, G., Kunst, M., Baier, H., Bormuth, V., Englitz, B. & Debregeas, G. (2021) Compositional restricted boltzmann machines unveil the brain-wide organization of neural assemblies, bioRxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter path to PGM package directory\n",
    "# This pacakge can be downloaded at https://github.com/jertubiana/PGM\n",
    "# Please follow installation instructions in README.md\n",
    "PGM_dir_path = ''  \n",
    "PGM_dir_path = 'C:/Users/luukh/OneDrive/Intern/PGM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numba import set_num_threads\n",
    "from numba import njit,prange\n",
    "set_num_threads(8) # Set the number of cores. Must be executed before importing numpy&numba.\n",
    "\n",
    "sys.path.append(PGM_dir_path + '/source/')\n",
    "sys.path.append(PGM_dir_path + '/utilities/')\n",
    "import RBM_utils\n",
    "import rbm, utilities\n",
    "\n",
    "from zebrafish_rtrbm.models.RBM import RBM\n",
    "from zebrafish_rtrbm.models.RTRBM import RTRBM\n",
    "\n",
    "from zebrafish_rtrbm.utils.data_methods import reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path2dataset):\n",
    "    f = h5py.File(path2dataset, 'r')\n",
    "    labels = f['Data']['Brain']['Labels'][:].T.astype('bool')\n",
    "    Coordinates = f['Data']['Brain']['Coordinates'][:].T # Spatial coordinates\n",
    "    Labels = f['Data']['Brain']['Labels'][:].T.astype('bool')\n",
    "    Spikes = f['Data']['Brain']['Analysis']['ThresholdedSpikes'][:].astype('bool')\n",
    "    f.close()\n",
    "\n",
    "    mask = Labels.max(-1) # Discard neurons not mapped to Zbrain atlas.\n",
    "    Spikes = Spikes[:,mask]\n",
    "    Coordinates = Coordinates[mask]\n",
    "\n",
    "    return Spikes,Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '../data/figure3_zebrafish'  # Directory path to save the model files to\n",
    "data_dir = 'C:/Users/luukh/OneDrive/Intern/RTRBM/data/figure3_zebrafish/'  # Directory path to save the model files to\n",
    "# models_dir = 'C:/Users/luukh/OneDrive/Intern/RTRBM/models/figure3_zebrafish/'\n",
    "\n",
    "list_datasets = [\n",
    "    'fish1_20180706_Run04',\n",
    "    'fish2_20180911_Run01',\n",
    "    'fish3_20180912_Run01',\n",
    "    'fish4_20180913_Run01',\n",
    "    'fish5_20190109_Run04',\n",
    "    'fish6_20181206_Run03',\n",
    "    'fish7_20190102_Run01',\n",
    "    'fish8_20181206_Run05',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_idx = 3 # The dataset used.\n",
    "path2dir = os.getcwd() + '/RTRBM/'\n",
    "\n",
    "list_datasets = [\n",
    "    'fish1_20180706_Run04',\n",
    "    'fish2_20180911_Run01',\n",
    "    'fish3_20180912_Run01',\n",
    "    'fish4_20180913_Run01',\n",
    "    'fish5_20190109_Run04',\n",
    "    'fish6_20181206_Run03',\n",
    "    'fish7_20190102_Run01',\n",
    "    'fish8_20181206_Run05',\n",
    "]\n",
    "\n",
    "dataset_idx = 3# The dataset used.\n",
    "dataset = list_datasets[dataset_idx]\n",
    "\n",
    "Spikes, Coordinates = load_dataset(data_dir + '/fish%s/rbm_%s.h5'%(dataset_idx+1, dataset))\n",
    "\n",
    "T, n_v = Spikes.shape\n",
    "print('Recording has %s time frames and %s neurons' %(T, n_v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data splitting\n",
    "\n",
    "The train/test split is defined by dividing the recording, with a length of T, into 10 chronological segments of equal length. The train batch consists of segments 1, 3, 4, 5, 8, 9, and 10, while the test batch consists of segments 2, 6, and 7. Since the neural recordings are from separate fish that are in different brain states at the beginning and during the recordings, it is not necessary for each fish to have a different train/test split segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_units = {\n",
    "'fish1_20180706_Run04':200,\n",
    "'fish2_20180911_Run01':200,\n",
    "'fish3_20180912_Run01':200,\n",
    "'fish4_20180913_Run01':200,\n",
    "'fish5_20190109_Run04':100,\n",
    "'fish6_20181206_Run03':200,\n",
    "'fish7_20190102_Run01':100,\n",
    "'fish8_20181206_Run05':100,\n",
    "                }\n",
    "\n",
    "learning_rates = {\n",
    "'fish1_20180706_Run04':1e-3,\n",
    "'fish2_20180911_Run01':1e-3,\n",
    "'fish3_20180912_Run01':1e-3,\n",
    "'fish4_20180913_Run01':2.5e-4,\n",
    "'fish5_20190109_Run04':1e-4,\n",
    "'fish6_20181206_Run03':2.5e-4,\n",
    "'fish7_20190102_Run01':1e-4,\n",
    "'fish8_20181206_Run05':2.5e-4,\n",
    "}\n",
    "\n",
    "batch_sizes = {\n",
    "'fish1_20180706_Run04':400,\n",
    "'fish2_20180911_Run01':100,\n",
    "'fish3_20180912_Run01':100,\n",
    "'fish4_20180913_Run01':100,\n",
    "'fish5_20190109_Run04':400,\n",
    "'fish6_20181206_Run03':100,\n",
    "'fish7_20190102_Run01':135,\n",
    "'fish8_20181206_Run05':100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(data):\n",
    "    batch_size = data.shape[1] // 10\n",
    "    train = torch.zeros(data.shape[0], batch_size, 7)\n",
    "    test = torch.zeros(data.shape[0], batch_size, 3)\n",
    "    batch_index_shuffled = [0, 2, 3, 4, 7, 8, 9, 1, 5, 6]\n",
    "    i = 0\n",
    "\n",
    "    for batch in range(10):\n",
    "        j = batch_index_shuffled[batch]\n",
    "        if batch < 7:\n",
    "            train[:, :, batch] = data[:, j * batch_size:(j + 1) * batch_size]\n",
    "        if batch >= 7:\n",
    "            test[:, :, batch-7] = data[:, j * batch_size:(j + 1) * batch_size]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cRBM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/figure3_zebrafish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path2crbm = data_dir + '/fish%s/rbm_%s_test.data'%(dataset_idx+1, dataset)\n",
    "\n",
    "n_h = n_hidden_units[dataset] # Number of hidden units.\n",
    "l1 = 0.02 # Sparse regularization strength.\n",
    "learning_rate = learning_rates[dataset] # Initial learning rate.\n",
    "batch_size = batch_sizes[dataset] # Batch size / number of MCMC chains.\n",
    "N_MC = 15 # Number of alternate Gibbs sampling steps performed between each gradient calculation (PCD algorithm)\n",
    "n_updates = 1 # Total number of gradient descent updates performed.\n",
    "RBM = rbm.RBM(n_v = n_v, # Number of visible units (neurons).\n",
    "              n_h = n_h, # Number of hidden units.\n",
    "              visible = 'Bernoulli', # Nature of visible units (Bernoulli = 0/1 values)\n",
    "              hidden = 'dReLU' # Nature of hidden units. double Rectified linear Units potential. hidden='Gaussian' reproduces the Hopfield model.\n",
    "             )\n",
    "\n",
    "# 2, 6, 7 test sets\n",
    "train, test = train_test_split(torch.tensor(Spikes.T))\n",
    "train, test = np.array(reshape(train)).T, np.array(reshape(test)).T\n",
    "\n",
    "n_iter = (n_updates // (train.shape[0] // batch_size))    # Number of epochs\n",
    "print('Starting fit, %s epochs' % n_iter)\n",
    "\n",
    "RBM.fit(train != 0,\n",
    "        l1=l1, # sparse l1 regularization.\n",
    "        n_iter=n_iter, # Number of epochs.\n",
    "        learning_rate=learning_rate, # The learning rate\n",
    "        batch_size=batch_size, # Batch size.\n",
    "        N_MC=N_MC, # Number of MCMC steps.\n",
    "        verbose=1,\n",
    "        vverbose=0,\n",
    "       )\n",
    "print('Finished fit, %s epochs' % n_iter)\n",
    "RBM = RBM_utils.swap_sign_RBM(RBM)\n",
    "RBM_utils.saveRBM(path2crbm, RBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## RTRBM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path2rtrbm = data_dir + '/fish%s/rtrbm_%s_transfer'%(dataset_idx+1, dataset)\n",
    "\n",
    "# 2, 6, 7 test sets\n",
    "train, test = train_test_split(torch.tensor(Spikes.T))\n",
    "train, test =reshape(train), reshape(test)\n",
    "\n",
    "train, test = reshape(train, T=T[dataset], n_batches=n_batches_train[dataset]), reshape(test, T=T[dataset], n_batches=n_batches_test[dataset])\n",
    "rtrbm = RTRBM(train, n_hidden=RBM.weights.shape[0])\n",
    "rtrbm.W = torch.tensor(RBM.weights, dtype=torch.float, device=rtrbm.device)\n",
    "rtrbm.params = [rtrbm.W, rtrbm.U, rtrbm.b_h, rtrbm.b_v, rtrbm.b_init]\n",
    "rtrbm.learn(n_epochs=5000, max_lr=1e-3, min_lr=5e-6, lr_schedule='geometric_decay',\n",
    "            batch_size=batch_sizes[dataset], CDk=15, mom=0.9, wc=0.0002, sp=1e-6, x=2, n=1000)\n",
    "torch.save(rtrbm, path2rtrbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
